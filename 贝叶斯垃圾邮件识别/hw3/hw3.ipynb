{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次作业以垃圾邮件分类任务为基础，要求提取文本特征并使用朴素贝叶斯算法进行垃圾邮件识别（调用已有工具包或自行实现）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务介绍\n",
    "电子邮件是互联网的一项重要服务，在大家的学习、工作和生活中会广泛使用。但是大家的邮箱常常被各种各样的垃圾邮件填充了。有统计显示，每天互联网上产生的垃圾邮件有几百亿近千亿的量级。因此，对电子邮件服务提供商来说，垃圾邮件过滤是一项重要功能。而朴素贝叶斯算法在垃圾邮件识别任务上一直表现非常好，至今仍然有很多系统在使用朴素贝叶斯算法作为基本的垃圾邮件识别算法。\n",
    "\n",
    "本次实验数据集来自[Trec06](https://plg.uwaterloo.ca/cgi-bin/cgiwrap/gvcormac/foo06)的中文垃圾邮件数据集，目录解压后包含三个文件夹，其中data目录下是所有的邮件（未分词），已分词好的邮件在data_cut目录下。邮件分为邮件头部分和正文部分，两部分之间一般有空行隔开。标签数据在label文件夹下，文件中每行是标签和对应的邮件路径。‘spam’表示垃圾邮件，‘ham’表示正常邮件。\n",
    "\n",
    "本次实验\n",
    "\n",
    "基本要求：\n",
    "1. 提取正文部分的文本特征；\n",
    "2. 划分训练集和测试集（可以借助工具包。一般笔记本就足够运行所有数据，认为实现困难或算力不够的同学可以采样一部分数据进行实验。）；\n",
    "3. 使用朴素贝叶斯算法完成垃圾邮件的分类与预测，要求测试集准确率Accuracy、精准率Precision、召回率Recall均高于0.9（本次实验可以使用已有的一些工具包完成如sklearn）；\n",
    "4. 对比特征数目（词表大小）对模型效果的影响；\n",
    "5. 提交代码和实验报告。\n",
    "\n",
    "扩展要求：\n",
    "1. 邮件头信息有时也可以协助判断垃圾邮件，欢迎学有余力的同学们尝试；\n",
    "2. 尝试自行实现朴素贝叶斯算法细节；\n",
    "3. 尝试对比不同的概率计算方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "提示：\n",
    "若调用已有工具包，sklearn中提供了一些可能会用到的类。\n",
    "'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # 提取文本特征向量的类\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB # 三种朴素贝叶斯算法，差别在于估计p(x|y)的方式\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # 数据集划分和网格搜索交叉验证\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # 评估指标\n",
    "RANDOM_SEED = 2025 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Computer_Science\\御风\\机器学习作业\\贝叶斯垃圾邮件识别\\hw3\n",
      "Current working directory: d:\\Computer_Science\\御风\\机器学习作业\\贝叶斯垃圾邮件识别\\hw3\n",
      "Contents: ['hw3.html', 'hw3.ipynb', 'hw3.md', 'hw3.py', 'trec06c-utf8']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(),'trec06c-utf8') # 数据目录\n",
    "print(os.getcwd())\n",
    "# First, let's check what's in your current directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Contents:\", os.listdir('.'))\n",
    "label_file = os.path.join(data_dir,'label','index') # 标签文件路径\n",
    "\n",
    "labels_array = [] # 存储标签\n",
    "texts_array = [] #存储文本\n",
    "\n",
    "with open(label_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        label,path = line.strip().split() # 分割标签和路径\n",
    "        # parts = line.strip().split() # 分割标签和路径\n",
    "        # label,path = parts[0],parts[1] # 获取标签和路径\n",
    "        if label == 'spam':\n",
    "            labels_array.append(1) # 将'spam'标签转换为1\n",
    "        else:\n",
    "            labels_array.append(0) # 将'ham'标签转换为0\n",
    "        \n",
    "        email_path = os.path.join(data_dir, path.replace('../data','data_cut')) # 构建邮件文件的完整路径\n",
    "        with open(email_path,'r',encoding='utf-8',errors='ignore') as email_f:\n",
    "            email_lines = email_f.readlines() # 读取邮件内容\n",
    "            is_body = False # 标记是否在邮件正文部分\n",
    "            email_text = [] # 存储邮件正文\n",
    "            for email_line in email_lines:\n",
    "                email_line = email_line.strip() # 去除行首尾空格\n",
    "                if email_line == '': # 如果是空行，表示正文开始\n",
    "                    is_body = True # 设置标记为True\n",
    "                if is_body:\n",
    "                    email_text += email_line.split() # 将正文行按空格分割并添加到email_text中\n",
    "            texts_array.append(' '.join(email_text)) # 将正文列表转换为字符串并添加到texts_array中\n",
    "\n",
    "labels = np.array(labels_array) # 转换为NumPy数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts_array, labels, test_size=0.2, random_state=RANDOM_SEED) # 划分数据集，80%训练集，20%测试集\n",
    "\n",
    "# 从训练集中划分出10%作为验证集 (方便调参数)\n",
    "train_indices, val_indices = train_test_split(np.arange(len(train_texts)),test_size=0.1, random_state=RANDOM_SEED) # 从训练集中划分出10%作为验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义分类器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union,Dict\n",
    "class NaiveBayes:\n",
    "    def __init__(self,max_df:Union[float,int]=1.0,min_df:Union[float,int]=1,tfidf:bool = False, type:str='multinomial') -> None:\n",
    "        '''\n",
    "        max_df: 特征向量的最大值，默认为1.0, 超过该阈值的词语会被过滤掉\n",
    "        min_df: 特征向量的最小文档频率，默认为1, 低于该阈值的词语会被过滤掉\n",
    "        tfidf: 是否使用TF-IDF特征向量，默认为False\n",
    "        type: 朴素贝叶斯分类器的类型，默认为'multinomial',可选值有'multinomial', 'bernoulli', 'complement'\n",
    "        '''\n",
    "        self.max_df = max_df\n",
    "        self.min_df = min_df\n",
    "        self.tfidf = tfidf\n",
    "        self.type = type\n",
    "\n",
    "    def fit(self,X,y) -> None:\n",
    "        '''\n",
    "        X: 文本数据\n",
    "        y: 标签\n",
    "        '''\n",
    "        if self.tfidf:\n",
    "            self.vectorizer = TfidfVectorizer(max_df=self.max_df, min_df=self.min_df) # 使用TF-IDF特征向量\n",
    "        else:\n",
    "            self.vectorizer = CountVectorizer(max_df=self.max_df, min_df=self.min_df) # 使用词频特征向量\n",
    "        \n",
    "        X = self.vectorizer.fit_transform(X) # 将文本数据转换为特征向量\n",
    "        print(X.shape) # 打印特征向量的形状\n",
    "        if self.type == 'multinomial':\n",
    "            self.model = MultinomialNB() # 使用多项式朴素贝叶斯分类器\n",
    "        elif self.type == 'bernoulli':\n",
    "            self.model = BernoulliNB() # 使用伯努利朴素贝叶斯分类器\n",
    "        elif self.type == 'complement':\n",
    "            self.model = ComplementNB() # 使用补充朴素贝叶斯分类器\n",
    "        else:\n",
    "            raise ValueError(\"Invalid type, must be one of 'multinomial', 'bernoulli', 'complement'\") # 如果类型不合法，抛出异常\n",
    "        self.model.fit(X, y) # 训练模型\n",
    "\n",
    "    def predict(self,X) -> np.ndarray:\n",
    "        '''\n",
    "        X: 文本数据\n",
    "        返回预测结果\n",
    "        '''\n",
    "        assert hasattr(self,'vectorizer'),'Please train the model first' # 确保模型已经训练\n",
    "        assert hasattr(self, 'model'),'Please train the model first' # 确保模型已经训练\n",
    "        X = self.vectorizer.transform(X) # 将文本数据转换为特征向量\n",
    "        return self.model.predict(X) # 返回预测结果\n",
    "\n",
    "\n",
    "    def get_params(self,deep:bool=True) -> Dict[str,Union[float,int,bool,str]]:\n",
    "        '''\n",
    "        返回模型参数\n",
    "        deep: 是否深度拷贝，默认为True\n",
    "        '''\n",
    "        return {\n",
    "            'max_df': self.max_df,\n",
    "            'min_df': self.min_df,\n",
    "            'tfidf': self.tfidf,\n",
    "            'type': self.type\n",
    "        }\n",
    "\n",
    "\n",
    "    def set_params(self,**params) -> 'NaiveBayes':\n",
    "        '''\n",
    "        设置模型参数\n",
    "        params: 参数字典\n",
    "        返回当前对象\n",
    "        '''\n",
    "        for param,value in params.items():\n",
    "            setattr(self, param, value) # 设置参数\n",
    "        return self # 返回当前对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练和测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51696, 65642)\n",
      "Params: {'max_df': 0.95, 'min_df': 5, 'tfidf': False, 'type': 'multinomial'}\n",
      "Accuracy: 0.9759\n",
      "Precision: 0.9810\n",
      "Recall: 0.9825\n",
      "F1: 0.9818\n"
     ]
    }
   ],
   "source": [
    "## Model multinomial Naive Bayes\n",
    "model = NaiveBayes(type='multinomial',min_df=5,max_df=0.95) # 创建朴素贝叶斯分类器对象\n",
    "# 至少出现5个词，最大出现频率为0.95\n",
    "model.fit(train_texts,train_labels) # 训练模型\n",
    "pred_test_labels = model.predict(test_texts) # 在测试集上进行预测\n",
    "# Fix the print statement - remove curly braces and fix the f1_score call\n",
    "print(f'data_cut')\n",
    "print(f'Params: {model.get_params()}')\n",
    "print(f'Accuracy: {accuracy_score(test_labels, pred_test_labels):.4f}')\n",
    "print(f'Precision: {precision_score(test_labels, pred_test_labels):.4f}')\n",
    "print(f'Recall: {recall_score(test_labels, pred_test_labels):.4f}')\n",
    "print(f'F1: {f1_score(test_labels, pred_test_labels):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51696, 65642)\n",
      "data_cut\n",
      "Params: {'max_df': 0.95, 'min_df': 5, 'tfidf': False, 'type': 'bernoulli'}\n",
      "Accuracy: 0.9290\n",
      "Precision: 0.9838\n",
      "Recall: 0.9073\n",
      "F1: 0.9440\n"
     ]
    }
   ],
   "source": [
    "## Model Bernoulli Naive Bayes\n",
    "model = NaiveBayes(type='bernoulli',min_df=5,max_df=0.95) # 创建朴素贝叶斯分类器对象\n",
    "# 至少出现5个词，最大出现频率为0.95\n",
    "model.fit(train_texts,train_labels) # 训练模型\n",
    "pred_test_labels = model.predict(test_texts) # 在测试集上进行预测\n",
    "# Fix the print statement - remove curly braces and fix the f1_score call\n",
    "print(f'data_cut')\n",
    "print(f'Params: {model.get_params()}')\n",
    "print(f'Accuracy: {accuracy_score(test_labels, pred_test_labels):.4f}')\n",
    "print(f'Precision: {precision_score(test_labels, pred_test_labels):.4f}')\n",
    "print(f'Recall: {recall_score(test_labels, pred_test_labels):.4f}')\n",
    "print(f'F1: {f1_score(test_labels, pred_test_labels):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51696, 65642)\n",
      "data_cut\n",
      "Params: {'max_df': 0.95, 'min_df': 5, 'tfidf': False, 'type': 'complement'}\n",
      "Accuracy: 0.9711\n",
      "Precision: 0.9817\n",
      "Recall: 0.9743\n",
      "F1: 0.9780\n"
     ]
    }
   ],
   "source": [
    "## Model Complement Naive Bayes\n",
    "model = NaiveBayes(type='complement',min_df=5,max_df=0.95) # 创建朴素贝叶斯分类器对象\n",
    "# 至少出现5个词，最大出现频率为0.95\n",
    "model.fit(train_texts,train_labels) # 训练模型\n",
    "pred_test_labels = model.predict(test_texts) # 在测试集上进行预测\n",
    "# Fix the print statement - remove curly braces and fix the f1_score call\n",
    "print(f'data_cut')\n",
    "print(f'Params: {model.get_params()}')\n",
    "print(f'Accuracy: {accuracy_score(test_labels, pred_test_labels):.4f}')\n",
    "print(f'Precision: {precision_score(test_labels, pred_test_labels):.4f}')\n",
    "print(f'Recall: {recall_score(test_labels, pred_test_labels):.4f}')\n",
    "print(f'F1: {f1_score(test_labels, pred_test_labels):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调试超参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 252 candidates, totalling 252 fits\n",
      "(51696, 183259)\n",
      "Best params: {'max_df': 1.0, 'min_df': 1, 'tfidf': True, 'type': 'multinomial'}\n",
      "Best score: 0.9853\n",
      "(51696, 183259)\n",
      "Best model params: {'max_df': 1.0, 'min_df': 1, 'tfidf': True, 'type': 'multinomial'}\n",
      "Accuracy: 0.9802\n",
      "Precision: 0.9788\n",
      "Recall: 0.9914\n",
      "F1: 0.9851\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_df':[1.0,0.999,0.998,0.997,0.996,0.995,0.99],\n",
    "    'min_df':range(1,7),\n",
    "    'tfidf':[True,False],\n",
    "    'type':['multinomial','bernoulli','complement']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(NaiveBayes(),params,cv=[(train_indices,val_indices)],scoring='f1',verbose=100,n_jobs=-1) # 网格搜索交叉验证\n",
    "grid_search.fit(train_texts,train_labels) # 训练模型\n",
    "print(f'Best params: {grid_search.best_params_}') # 打印最佳参数\n",
    "print(f'Best score: {grid_search.best_score_:.4f}') # 打印最佳得分\n",
    "best_model = NaiveBayes(**grid_search.best_params_) # 创建最佳模型\n",
    "best_model.fit(train_texts, train_labels) # 训练最佳模型\n",
    "pred_test_labels = best_model.predict(test_texts) # 在测试集上进行预测\n",
    "print(f'Best model params: {best_model.get_params()}') # 打印最佳模型参数\n",
    "print(f'Accuracy: {accuracy_score(test_labels, pred_test_labels):.4f}') # 打印准确率\n",
    "print(f'Precision: {precision_score(test_labels, pred_test_labels):.4f}')\n",
    "print(f'Recall: {recall_score(test_labels, pred_test_labels):.4f}') # 打印召回率\n",
    "print(f'F1: {f1_score(test_labels, pred_test_labels):.4f}') # 打印F1分数\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
